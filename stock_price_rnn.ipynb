{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6cbd86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")#it will ignore if any warning is returned for packages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eb3212",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Tesla.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759373e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check the information of the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ff621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and validation data\n",
    "length_data = len(data)     #total no of rows in the data\n",
    "\n",
    "split_ratio = 0.7           # %70 train + %30 validation\n",
    "length_train = round(length_data * split_ratio)  \n",
    "length_validation = length_data - length_train\n",
    "print(\"Data length :\", length_data)\n",
    "print(\"Train data length :\", length_train)\n",
    "print(\"Validation data lenth :\", length_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5159b04",
   "metadata": {},
   "source": [
    "Fetching Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ce7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:length_train].iloc[:,:2] \n",
    "train_data['Date'] = pd.to_datetime(train_data['Date'])  # converting to date time object\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b2b903",
   "metadata": {},
   "source": [
    "Fetching Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7a31bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = data[length_train:].iloc[:,:2]\n",
    "validation_data['Date'] = pd.to_datetime(validation_data['Date'])  # converting to date time object\n",
    "print(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73db0dab",
   "metadata": {},
   "source": [
    "Creating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd8954",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = train_data.Open.values\n",
    "dataset_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc76f708",
   "metadata": {},
   "source": [
    "Converting data frame to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60313ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 1d array to 2d array\n",
    "# Changing shape from (1692,) to (1692,1)\n",
    "dataset_train = np.reshape(dataset_train, (-1,1))\n",
    "print(dataset_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b93509",
   "metadata": {},
   "source": [
    "Scaling the data (Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1792a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "\n",
    "# scaling dataset\n",
    "dataset_train_scaled = scaler.fit_transform(dataset_train)\n",
    "\n",
    "print(dataset_train_scaled.shape)\n",
    "print(\"\\n\",dataset_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b7d36a",
   "metadata": {},
   "source": [
    "Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af75863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,6))\n",
    "plt.plot(dataset_train_scaled)\n",
    "plt.xlabel(\"Days as 1st, 2nd, 3rd..\")\n",
    "plt.ylabel(\"Open Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb3779",
   "metadata": {},
   "source": [
    "Splitting the data in Xtrain and ytrain, for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ffff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "time_step = 50\n",
    "\n",
    "for i in range(time_step, length_train):\n",
    "    X_train.append(dataset_train_scaled[i-time_step:i,0])\n",
    "    y_train.append(dataset_train_scaled[i,0])\n",
    "    \n",
    "# convert list to array\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "print(X_train)#for checking\n",
    "print(y_train)# for checking\n",
    "\n",
    "print(\"\\nShape of X_train before reshape :\",X_train.shape)#to check\n",
    "print(\"\\nShape of y_train before reshape :\",y_train.shape)#to check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899aad7d",
   "metadata": {},
   "source": [
    "Reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8fb9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "y_train = np.reshape(y_train, (y_train.shape[0],1))\n",
    "\n",
    "print(\"Shape of X_train after reshape :\",X_train.shape)\n",
    "print(\"Shape of y_train after reshape :\",y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8653903",
   "metadata": {},
   "source": [
    "Creating RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1110c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# initializing the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# adding first RNN layer and dropout regulatization\n",
    "regressor.add(\n",
    "    SimpleRNN(units = 50, \n",
    "              activation = \"tanh\", \n",
    "              return_sequences = True, \n",
    "              input_shape = (X_train.shape[1],1))\n",
    "             )\n",
    "\n",
    "regressor.add(\n",
    "    Dropout(0.2)\n",
    "             )\n",
    "\n",
    "\n",
    "# adding second RNN layer and dropout regulatization\n",
    "regressor.add(\n",
    "    SimpleRNN(units = 50, \n",
    "              activation = \"tanh\", \n",
    "              return_sequences = True)\n",
    "             )\n",
    "\n",
    "regressor.add(\n",
    "    Dropout(0.2)\n",
    "             )\n",
    "\n",
    "# adding third RNN layer and dropout regulatization\n",
    "\n",
    "regressor.add(\n",
    "    SimpleRNN(units = 50, \n",
    "              activation = \"tanh\", \n",
    "              return_sequences = True)\n",
    "             )\n",
    "\n",
    "regressor.add(\n",
    "    Dropout(0.2)\n",
    "             )\n",
    "\n",
    "# adding fourth RNN layer and dropout regulatization\n",
    "\n",
    "regressor.add(\n",
    "    SimpleRNN(units = 50))\n",
    "\n",
    "regressor.add(\n",
    "    Dropout(0.2))\n",
    "\n",
    "# adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# compiling RNN\n",
    "regressor.compile(\n",
    "    optimizer = \"adam\", \n",
    "    loss = \"mean_squared_error\",\n",
    "    metrics = [\"accuracy\"])\n",
    "\n",
    "# fitting the RNN\n",
    "history = regressor.fit(X_train, y_train, epochs = 50, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b94429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing Losses\n",
    "history.history[\"loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d99b424",
   "metadata": {},
   "source": [
    "Printing losses in graphical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cdaa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Loss vs Epochs\n",
    "plt.figure(figsize =(10,7))\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Losses\")\n",
    "plt.title(\"Simple RNN model, Loss vs Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0064979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Accuracy vs Epochs\n",
    "plt.figure(figsize =(10,5))\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracies\")\n",
    "plt.title(\"Simple RNN model, Accuracy vs Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9c1227",
   "metadata": {},
   "source": [
    "Prediction using train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c347a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_train)  # predictions\n",
    "y_pred = scaler.inverse_transform(y_pred) # scaling back from 0-1 to original\n",
    "print(y_pred.shape)\n",
    "print(\"\\n\",\" y_pred:\",y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c052312d",
   "metadata": {},
   "source": [
    "As we have used Xtrain for making predictions, thus ytrain will be used for checking accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0092ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = scaler.inverse_transform(y_train) # scaling back from 0-1 to original\n",
    "print(y_train.shape)\n",
    "print(\"\\n\",\" y_train:\",y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "plt.figure(figsize = (30,10))\n",
    "plt.plot(y_pred, color = \"b\", label = \"y_pred\" )\n",
    "plt.plot(y_train, color = \"g\", label = \"y_train\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Open price\")\n",
    "plt.title(\"Simple RNN model, Predictions with input X_train vs y_train\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ac6e7",
   "metadata": {},
   "source": [
    "Creating test dataset from Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d37e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting array and scaling\n",
    "dataset_validation = validation_data.Open.values  # getting \"open\" column and converting to array\n",
    "dataset_validation = np.reshape(dataset_validation, (-1,1))  # converting 1D to 2D array\n",
    "scaled_dataset_validation =  scaler.fit_transform(dataset_validation)  # scaling open values to between 0 and 1\n",
    "print(\"Shape of scaled validation dataset :\",scaled_dataset_validation.shape)\n",
    "\n",
    "# Creating X_test and y_test\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(time_step, length_validation):\n",
    "    X_test.append(scaled_dataset_validation[i-time_step:i,0])\n",
    "    y_test.append(scaled_dataset_validation[i,0])\n",
    "\n",
    "# Converting to array\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "print(\"Shape of X_test before reshape :\",X_test.shape)\n",
    "print(\"Shape of y_test before reshape :\",y_test.shape)\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))  # reshape to 3D array\n",
    "y_test = np.reshape(y_test, (-1,1))  # reshape to 2D array\n",
    "\n",
    "print(\"Shape of X_test after reshape :\",X_test.shape)\n",
    "print(\"Shape of y_test after reshape :\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2543e5b6",
   "metadata": {},
   "source": [
    "Evaluating with Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0a79d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions with X_test data\n",
    "y_pred_of_test = regressor.predict(X_test)\n",
    "# scaling back from 0-1 to original\n",
    "y_pred_of_test = scaler.inverse_transform(y_pred_of_test) \n",
    "print(\"Shape of y_pred_of_test :\",y_pred_of_test.shape)\n",
    "\n",
    "# visualisation\n",
    "plt.figure(figsize = (30,10))\n",
    "plt.plot(y_pred_of_test, label = \"y_pred_of_test\", c = \"orange\")\n",
    "plt.plot(scaler.inverse_transform(y_test), label = \"y_test\", c = \"g\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Open price\")\n",
    "plt.title(\"Simple RNN model, Prediction with input X_test vs y_test\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Visualisation\n",
    "plt.subplots(figsize =(30,12))\n",
    "plt.plot(train_data.Date, train_data.Open, label = \"train_data\", color = \"b\")\n",
    "plt.plot(validation_data.Date, validation_data.Open, label = \"validation_data\", color = \"g\")\n",
    "plt.plot(train_data.Date.iloc[time_step:], y_pred, label = \"y_pred\", color = \"r\")\n",
    "plt.plot(validation_data.Date.iloc[time_step:], y_pred_of_test, label = \"y_pred_of_test\", color = \"orange\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Open price\")\n",
    "plt.title(\"Simple RNN model, Train-Validation-Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cff38c",
   "metadata": {},
   "source": [
    "CREATING LSTM MODEL- Long Short Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = scaler.fit_transform(y_train)\n",
    "\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(\n",
    "    LSTM(64,return_sequences=True,input_shape = (X_train.shape[1],1))) #64 lstm neuron block\n",
    "model_lstm.add(\n",
    "    LSTM(64, return_sequences= False))\n",
    "model_lstm.add(Dense(32))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(loss = \"mean_squared_error\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "history2 = model_lstm.fit(X_train, y_train, epochs = 10, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b80c42",
   "metadata": {},
   "source": [
    "Evaluating LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c730ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(10,5))\n",
    "plt.plot(history2.history[\"loss\"])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Losses\")\n",
    "plt.title(\"LSTM model, Accuracy vs Epoch\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ee4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize =(30,12))\n",
    "plt.plot(scaler.inverse_transform(model_lstm.predict(X_test)), label = \"y_pred_of_test\", c = \"orange\" )\n",
    "plt.plot(scaler.inverse_transform(y_test), label = \"y_test\", color = \"g\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Open price\")\n",
    "plt.title(\"LSTM model, Predictions with input X_test vs y_test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbccedb",
   "metadata": {},
   "source": [
    "Future Price prediction\n",
    "\n",
    "Which day is the last day in our data?\n",
    "We can predict the open price for the day after 3/17/2017--> for 3/18/2017.\n",
    "We will use last 50 days Open price as input of our model for this prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bccaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7b1e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = data.iloc[-time_step:].Open.values               # getting last 50 rows and converting to array\n",
    "X_input = scaler.fit_transform(X_input.reshape(-1,1))      # converting to 2D array and scaling\n",
    "X_input = np.reshape(X_input, (1,50,1))                    # reshaping : converting to 3D array\n",
    "print(\"Shape of X_input :\", X_input.shape)\n",
    "print(X_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498e601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_RNN_prediction = scaler.inverse_transform(regressor.predict(X_input))\n",
    "LSTM_prediction = scaler.inverse_transform(model_lstm.predict(X_input))\n",
    "print(\"Simple RNN, Open price prediction for 3/18/2017      :\", simple_RNN_prediction[0,0])\n",
    "print(\"LSTM prediction, Open price prediction for 3/18/2017 :\", LSTM_prediction[0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
